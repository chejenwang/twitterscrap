# Author= Che Jen Wang
# Date:  2020/9/17
# the purpose of the script is to download the CGTN twitter account data.
# We like to retrieve the tweet text, comments, re-tweet, likes


# reference pages:
# https://zhuanlan.zhihu.com/p/165521124
# https://www.geeksforgeeks.org/twitter-automation-using-selenium-python/
# https://blog.csdn.net/weixin_44076842/article/details/104392580



from selenium import webdriver 
from selenium.webdriver.common.keys import Keys 
from selenium.webdriver import ActionChains 
from selenium.webdriver.chrome.options import Options 
'''Uncomment the below line when running in linux'''
# from pyvirtualdisplay import Display 
import time, os 

# Replace your_twitter_email_account with your email account 
#myemail="your_twitter_email_account"

# replace XXXXXXXXXXXXX with your password
#mypassword="XXXXXXXXXXXXXXXX"


#loading twitter
driver=webdriver.Chrome()
driver.get('https://twitter.com/login') 
time.sleep(4) #wait for 4 seconds to load the page

# Log in with email and password
email = driver.find_element_by_name("session[username_or_email]")
password = driver.find_element_by_name("session[password]")
email.send_keys(myemail) 
password.send_keys(mypassword)
password.send_keys(Keys.RETURN)
time.sleep(3)  #wait for 3 second to login and load the pages


#input_name = input("请输入爬取用户的id:(如爬取用户id为@KingJames，则输入:KingJames)")
input_name=CGTNOfficial
user_url='https://www.twitter.com/CGTNOfficial/

#首先是创建存储数据的文件
csv_path_1 = (file_path +'{}/'.format(input_name)+ '{}的推文数据.csv'.format(input_name))
with open(csv_path_1, 'w', newline='', encoding="utf_8_sig") as f:
    writer = csv.writer(f)
    head = ["用户id", "推文内容", "推文时间", "评论数", "转发数", "喜欢数", "链接"]
    writer.writerow(head)


old_scroll_height = 0 #表明页面在最上端
js1 = 'return document.body.scrollHeight'#获取页面高度的javascript语句
js2 = 'window.scrollTo(0, document.body.scrollHeight)'#将页面下拉的Javascript语句
while (browser.execute_script(js1) > old_scroll_height):#将当前页面高度与上一次的页面高度进行对比
    old_scroll_height = browser.execute_script(js1)#获取到当前页面高度
    browser.execute_script(js2)#操控浏览器进行下拉
    time.sleep(1.5)#空出加载的时间


#由于转发、评论、点赞的爬取代码一样，故以函数方法表示
def count(crd):
	if "K" in crd.text:
	    comment_number = int(float((crd.text)[:-1]) * 1000)  # 将带有千字的数据转化为整数
	elif "M" in crd.text:
	    comment_number = int(float((crd.text)[:-1]) * 1000000)  # 将带有万字的数据转化为整数
	else:  # 没有带千字或万字
	    if crd.text:
	        comment_number = int(crd.text)
	    else:  # 若不存在数据，则设为0
	        comment_number = 0
	return comment_number

content = bs(browser.page_source, 'html.parser')
#使用Beautifulsoup读取selenium获取到的网页内容
tw_user_1=content.find_all('article',re.compile('css-1dbjc4n r-1loqt21 r-1udh08x'))
#采用正则表达式re来实现用户推文的搜索，避免因为后续标签属性的改变而导致无法定位
print("已获取到{}条推文(可能有重复推文)".format(len(tw_user_1)))

#获取用户发布的推文数据
user_content=content.find_all('article',re.compile('css-1dbjc4n r-1loqt21 r-1udh08x'))#获取到当前加载的所有推文数据
for i in range(len(user_content)):#遍历所有数据
    w_text=user_content[i].find('div',re.compile('r-a023e6 r-16dba41 r-ad9z0x r-bcqeeo r-bnwqim r-qvutc0'))
    #获取到当前推文的内容
    if w_text:#判断是否有推文内容，因为存在转推的情况
        tw_text=w_text.text
    else:
        tw_text='该推文无文字内容（编号：{}）'.format(m)
        m=m+1
    if tw_text not in tw_list:#可能存在同一推文被再次爬取，因此需要判断。
        tw_number = tw_number + 1
        tw_list.append(tw_text)
        tw_data['user']=user_content[i].find('div','css-1dbjc4n r-18u37iz r-1wbh5a2 r-1f6r7vd').text#获取推特用户id
        tw_data['text']=tw_text.rstrip()
        #获取评论数，转发数，点赞数
        crd=user_content[i].find_all('div','css-1dbjc4n r-1iusvr4 r-18u37iz r-16y2uox r-1h0z5md')
        #定位到评论数，点赞数，转发数所在的标签
        comment_number=count(crd[0])
        tw_data['comment'] = comment_number
        return_number=count(crd[1])
        tw_data['return'] = return_number
        like_number=count(crd[2])
        tw_data['like'] = like_number
        tw_data['time'] = user_content[i].find('time')['datetime'][:-5]#推文时间
        tw_data['href']= 'http://twitter.com/'+user_content[i].find('a',
                                'css-4rbku5 css-18t94o4 css-901oao r-1re7ezh r-1loqt21'
                                ' r-1q142lx r-1qd0xha r-a023e6 r-16dba41 r-ad9z0x r-bcqeeo r-3s2u2q r-qvutc0')['href']
        #将每一次循环爬取到的数据以追加的方式写入已经创建好的csv文件中
        tw_data.to_csv(file_path + '\\{}'.format(input_name) + '\\{}的推文数据.csv'.format(input_name), mode='a',
               header=False, index=False, encoding="utf_8_sig")
    else:
        continue



#############################################
## codes below this is for reference only  ##
#############################################
# class Twitterbot: 
  
#     def __init__(self, email, password): 
  
#         """Constructor 
  
#         Arguments: 
#             email {string} -- registered twitter email 
#             password {string} -- password for the twitter account 
#         """
  
#         self.email = email 
#         self.password = password 
#         # initializing chrome options 
#         chrome_options = Options() 
  
#         # adding the path to the chrome driver and  
#         # integrating chrome_options with the bot 
#         self.bot = webdriver.Chrome( 
#             executable_path = os.path.join(os.getcwd(), 'chromedriver'), 
#             options = chrome_options 
#         ) 
  
#     def login(self): 
#         """ 
#             Method for signing in the user  
#             with the provided email and password. 
#         """
  
#         bot = self.bot 
#         # fetches the login page 
#         bot.get('https://twitter.com / login') 
#         # adjust the sleep time according to your internet speed 
#         time.sleep(3) 
  
#         email = bot.find_element_by_xpath( 
#             '//*[@id ="react-root"]/div / div / div[2]/main / div / div / form / div / div[1]/label / div / div[2]/div / input'
#         ) 
#         password = bot.find_element_by_xpath( 
#             '//*[@id ="react-root"]/div / div / div[2]/main / div / div / form / div / div[2]/label / div / div[2]/div / input'
#         ) 
  
#         # sends the email to the email input 
#         email.send_keys(self.email) 
#         # sends the password to the password input 
#         password.send_keys(self.password) 
#         # executes RETURN key action 
#         password.send_keys(Keys.RETURN) 
  
#         time.sleep(2) 
  
#     def like_retweet(self, hashtag): 
  
#         """ 
#         This function automatically retrieves 
#         the tweets and then likes and retweets them 
  
#         Arguments: 
#             hashtag {string} -- twitter hashtag 
#         """
  
#         bot = self.bot 
  
#         # fetches the latest tweets with the provided hashtag 
#         bot.get( 
#             'https://twitter.com / search?q =% 23' + \ 
#             hashtag+'&src = typed_query&f = live'
#         ) 
  
#         time.sleep(3) 
  
#         # using set so that only unique links 
#         # are present and to avoid unnecessary repetition 
#         links = set()  
  
#         # obtaining the links of the tweets 
#         for _ in range(100): 
#             # executing javascript code  
#             # to scroll the webpage 
#             bot.execute_script( 
#                 'window.scrollTo(0, document.body.scrollHeight)'
#             ) 
  
#             time.sleep(4) 
  
#             # using list comprehension  
#             # for adding all the tweets link to the set 
#             # this particular piece of code might 
#             # look very complicated but the only reason 
#             # I opted for list comprehension because is 
#             # lot faster than traditional loops 
#             [ 
#                 links.add(elem.get_attribute('href'))\ 
#                 for elem in bot.find_elements_by_xpath("//a[@dir ='auto']") 
#             ] 
  
#         # traversing through the generated links 
#         for link in links: 
#             # opens individual links 
#             bot.get(link) 
#             time.sleep(4) 
  
#             try: 
#                 # retweet button selector 
#                 bot.find_element_by_css_selector( 
#                     '.css-18t94o4[data-testid ="retweet"]'
#                 ).click() 
#                 # initializes action chain 
#                 actions = ActionChains(bot) 
#                 # sends RETURN key to retweet without comment 
#                 actions.send_keys(Keys.RETURN).perform() 
  
#                 # like button selector 
#                 bot.find_element_by_css_selector( 
#                     '.css-18t94o4[data-testid ="like"]'
#                 ).click() 
#                 # adding higher sleep time to avoid 
#                 # getting detected as bot by twitter 
#                 time.sleep(10) 
#             except: 
#                 time.sleep(2) 
  
#         # fetches the main homepage 
#         bot.get('https://twitter.com/') 
# Now, it’s time to code our driver script. To do that, create a file called main.py and add the following lines to it.

# filter_none
# brightness_4
# import twitterbot as tb 
# import secrets, sys 
  
# # fetches the hashtag from command line argument 
# hashtag = sys.argv[1] 
# # fetches the credentials dictionary 
# # using get_credentials function 
# credentials = secrets.get_credentials() 
# # initialize the bot with your credentials 
# bot = tb.Twitterbot(credentials['email'], credentials['password']) 
# # loging in 
# bot.login() 
# # calling like_retweet function 
# bot.like_retweet(hashtag) 
